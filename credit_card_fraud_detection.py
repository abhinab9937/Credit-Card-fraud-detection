# -*- coding: utf-8 -*-
"""Credit_Card_Fraud_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jEUJoDUp_c6pNXz8hi4uxcoWuF5aO4qh
"""

#importing necessary modules
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import itertools
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score

dataframe = pd.read_csv("creditcard.csv")
dataframe.head()

dataframe.info()

dataframe.isnull().values.any()

dataframe["Amount"].describe()

non_fraud = len(dataframe[dataframe.Class == 0])
fraud = len(dataframe[dataframe.Class == 1])
fraud_percent = (fraud / (fraud + non_fraud))*100
print("Number of genuine transactions:", non_fraud)
print("Number of Fraud Transactions:", fraud)
print("Percentage of Fraud Transactions: {:.4f}".format(fraud_percent))

labels = ["Genuine","Fraud"]
count_classes = dataframe.value_counts(dataframe['Class'], sort = True)
count_classes.plot(kind = "bar", rot = 0)
plt.title("Visualization of labels")
plt.ylabel("Count")
plt.xticks(range(2), labels)
plt.show()

# perform Scaling
scaler = StandardScaler()
dataframe["NormalizedAmount"] =  scaler.fit_transform(dataframe["Amount"].values.reshape(-1,1))
dataframe.drop(["Amount","Time"], inplace = True, axis =1)
Y = dataframe["Class"]
X = dataframe.drop(["Class"], axis = 1)

Y.head()

(train_X, test_X, train_Y, test_Y) = train_test_split(X, Y, test_size= 0.3, random_state= 42)

print("Shape of train_X: ", train_X.shape)
print("Shape of test_X: ", test_X.shape)

import pandas as pd
from sklearn.tree import DecisionTreeClassifier

# ✅ Combine X and Y temporarily to drop rows with missing labels
train_data = pd.concat([train_X, train_Y], axis=1)

# Drop rows where target (Y) is NaN
train_data = train_data.dropna(subset=[train_Y.name])

# Split cleaned data back into X and Y
train_X_clean = train_data.drop(columns=[train_Y.name])
train_Y_clean = train_data[train_Y.name]

# ✅ Train the Decision Tree
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(train_X_clean, train_Y_clean)

# ✅ Predict & Score
predictions_dt = decision_tree.predict(test_X)
decision_tree_score = decision_tree.score(test_X, test_Y) * 100

print(f"Decision Tree Accuracy: {decision_tree_score:.2f}%")

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# ✅ Combine training data
train_data = pd.concat([train_X, train_Y], axis=1)

# ✅ Drop rows where Y is missing
train_data = train_data.dropna(subset=[train_Y.name])

# ✅ Split back into X and Y
train_X_clean = train_data.drop(columns=[train_Y.name])
train_Y_clean = train_data[train_Y.name]

# ✅ Fill missing values in features (X) if any
train_X_clean = train_X_clean.fillna(train_X_clean.median())
test_X = test_X.fillna(test_X.median())
test_Y = test_Y.fillna(test_Y.mode()[0])  # Fill Y in test set if needed

# =======================
# DECISION TREE
# =======================
decision_tree = DecisionTreeClassifier(random_state=42)
decision_tree.fit(train_X_clean, train_Y_clean)

predictions_dt = decision_tree.predict(test_X)
decision_tree_score = decision_tree.score(test_X, test_Y) * 100
print(f"Decision Tree Accuracy: {decision_tree_score:.2f}%")

# =======================
# RANDOM FOREST
# =======================
random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest.fit(train_X_clean, train_Y_clean)

predictions_rf = random_forest.predict(test_X)
random_forest_score = random_forest.score(test_X, test_Y) * 100
print(f"Random Forest Accuracy: {random_forest_score:.2f}%")

print("Random Forest Score: ", random_forest_score)
print("Decision Tree Score: ", decision_tree_score)

# plotting the confusion matrix
# The below function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=0)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment="center", color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# plotting confusion matrix for DECISON TREES
confusion_matrix_dt = confusion_matrix(test_Y, predictions_dt.round())
print("Confusion Matrix - Decision Tree")
print(confusion_matrix_dt)

plot_confusion_matrix(confusion_matrix_dt, classes=[0, 1], title= "Confusion Matrix - Decision Tree")

# plotting confusion matrix for RANDOM FOREST
confusion_matrix_rf = confusion_matrix(test_Y, predictions_rf.round())
print("Confusion Matrix - Random Forest")
print(confusion_matrix_rf)

plot_confusion_matrix(confusion_matrix_rf, classes=[0, 1], title= "Confusion Matrix - Random Forest")

def metrics(actuals, predictions):
    print("Accuracy: {:.5f}".format(accuracy_score(actuals, predictions)))
    print("Precision: {:.5f}".format(precision_score(actuals, predictions)))
    print("Recall: {:.5f}".format(recall_score(actuals, predictions)))
    print("F1-score: {:.5f}".format(f1_score(actuals, predictions)))

print("Evaluation of Decision Tree Model")
print()
metrics(test_Y, predictions_dt.round())

print("Evaluation of Random Forest Model")
print()
metrics(test_Y, predictions_rf.round())

import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from collections import Counter

# ✅ 1. Drop rows where Y is missing
data = pd.concat([X, Y], axis=1)
data = data.dropna(subset=[Y.name])  # Drop rows with NaN labels

# ✅ 2. Separate features & labels
X_clean = data.drop(columns=[Y.name])
Y_clean = data[Y.name]

# ✅ 3. Fill missing values in X (numeric only)
X_clean = X_clean.fillna(X_clean.median())

# ✅ 4. Apply SMOTE for balancing
smote = SMOTE(random_state=42)
X_resampled, Y_resampled = smote.fit_resample(X_clean, Y_clean)

print("✅ After SMOTE:")
print("X shape:", X_resampled.shape)
print("Y shape:", Y_resampled.shape)
print("Class distribution:", Counter(Y_resampled))

# ✅ 5. Train/test split
train_X, test_X, train_Y, test_Y = train_test_split(
    X_resampled, Y_resampled, test_size=0.3, random_state=42
)

# Building the Random Forest classifier on a new dataset

rf_resampled = RandomForestClassifier(n_estimators = 100)
rf_resampled.fit(train_X, train_Y)

predictions_resampled = rf_resampled.predict(test_X)
random_forest_score_resampled = rf_resampled.score(test_X, test_Y) * 100

# Visualizing the confusion matrix

cm_resampled = confusion_matrix(test_Y, predictions_resampled.round())
print("Confusion Matrix - Random Forest")
print(cm_resampled)

plot_confusion_matrix(cm_resampled, classes=[0, 1], title= "Confusion Matrix - Random Forest After Oversampling")

print("Evaluation of Random Forest Model")
print()
metrics(test_Y, predictions_resampled.round())